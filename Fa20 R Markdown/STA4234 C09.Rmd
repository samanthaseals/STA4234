---
title: 'STA4234: Chapter 9 Examples'
date: "Last updated: `r Sys.Date()`"
output: 
  html_document:
      toc: TRUE
      toc_depth: 5
      toc_float: TRUE
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pander)

### p.value.string v2
# Update v2: added the formatting that turns of scientific notation
# fixes the case when p = 0.0001 (instead of p=1e-4)
# This function called p.value.string creates a string
# to be used when reporting the p-value. It includes the p on the LHS.
# You will likely place it in $$ to get the LaTeX math formatting.
# This should be placed in an r code chunk in the beginning of your R markdown
# This code chunk by itself shouldn't produce any result.
# by Reid Ginoza

p.value.string = function(p.value){
  p.value <- round(p.value, digits=4)
  if (p.value == 0) {
    return("p < 0.0001")
  } else {
    return(paste0("p = ", format(p.value, scientific = F)))
  }
}
```

## Example 1

The following data are weight ($Y$), height ($X_1$), and age ($X_2$) for a sample of 12 children. 

```{r}
wgt <- c(64, 71, 53, 67, 55, 58, 77, 57, 56, 51, 76, 68)
hgt <- c(57, 59, 49, 62, 51, 50, 55, 48, 42, 42, 61, 57)
age <- c(8, 10, 6, 11, 8, 7, 10, 9, 10, 6, 12, 9)

one <- tibble(wgt, hgt, age)

# create age^2 variable
one$age2 <- one$age^2
```

### Model 1 (wgt ~ hgt + age + age$^2$)

```{r}
one_m1 <- lm(wgt ~ hgt + age + age2, data=one)
one_m1_coef <- coefficients(one_m1)

summary(one_m1)
```

#### Model

The resulting regression model is 
\[ \hat{Y} = `r round(one_m1_coef[[1]], digits = 2)` + `r round(one_m1_coef[[2]], digits=2)`X_1 + `r round(one_m1_coef[[3]], digits=2)`X_2 `r round(one_m1_coef[[4]], digits=2)`X_2^2 \]

#### Omnibus test

```{r}
one_summary <- summary(one_m1)
```


**Hypotheses**

&emsp;&emsp; $H_0: \ \beta_1 = \beta_2 = \beta_3 = 0$ <br>
&emsp;&emsp; $H_1:$  at least one $\beta_i \ne 0$

**Test Statistic**

&emsp;&emsp; $F_0 = `r round(one_summary[[10]][1], digits=2)`$.

***p*-value**

&emsp;&emsp; $`r p.value.string(pf(one_summary[[10]][1], one_summary[[10]][2], one_summary[[10]][3], lower.tail = FALSE))`$.

**Rejection Region**

&emsp;&emsp; Reject if $p < \alpha$, where $\alpha=0.05$.

**Conclusion and Interpretation**

&emsp;&emsp; Reject $H_0$. There is sufficient evidence to suggest that the regression line is significant.

#### Partial F tests

##### Height alone
```{r}
# hgt
full = lm(wgt ~ hgt, data=one) # Full Model

out <- anova(full) 
```

`r pander(out, style='rmarkdown')`

##### Age after adjusting for height
```{r}
# age
full = lm(wgt ~ hgt + age, data=one) # Full Model
reduced = lm(wgt ~ hgt, data=one) # Reduced model

out <- anova(reduced, full) # Compare the models
```

`r pander(out, style='rmarkdown')`

##### Age$^2$ after adjusting for height and age

```{r}
# age^2
full = lm(wgt ~ hgt + age + age2, data=one) # Full Model
reduced = lm(wgt ~ hgt + age, data=one) # Reduced model

out <- anova(reduced, full) # Compare the models
```

`r pander(out, style='rmarkdown')`

#### Multiple partial $F$ tests

##### Age and age$^2$ after adjusting for height

```{r}
# age^2
full = lm(wgt ~ hgt + age + age2, data=one) # Full Model
reduced = lm(wgt ~ hgt, data=one) # Reduced model

out <- anova(reduced, full) # Compare the models
```

`r pander(out, style='rmarkdown')`

#### Variable added last $F$ tests

```{r}
one_typeIII_m1 <- drop1(one_m1, .~., test="F")
```

The corresponding ANOVA table is as follows

`r pander(one_typeIII_m1, style='rmarkdown')`

#### $t$ tests 

`r pander(one_summary[[4]], style='rmarkdown')`

#### 95% confidence interval for $\beta_i$
```{r}
one_ci <- as_tibble(confint(one_m1, level=0.95))
```

The confidence interval for the slope of height is (`r round(one_ci$"2.5 %"[2], digits = 2)`, `r round(one_ci$"97.5 %"[2], digits = 2)`).

The confidence interval for the slope of age is (`r round(one_ci$"2.5 %"[3], digits = 2)`, `r round(one_ci$"97.5 %"[3], digits = 2)`).

The confidence interval for the slope of age$^2$ is (`r round(one_ci$"2.5 %"[4], digits = 2)`, `r round(one_ci$"97.5 %"[4], digits = 2)`).







### Model 2 (wgt ~ hgt + age)

```{r}
one_m2 <- lm(wgt ~ hgt + age, data=one)
one_m2_coef <- coefficients(one_m2)
```

#### Model 

The resulting regression model is 
\[ \hat{Y} = `r round(one_m2_coef[[1]], digits = 2)` + `r round(one_m2_coef[[2]], digits=2)`X_1 + `r round(one_m2_coef[[3]], digits=2)`X_2  \]

#### Omnibus test

```{r}
one_summary <- summary(one_m2)
```

**Hypotheses**

&emsp;&emsp; $H_0: \ \beta_1 = \beta_2 = 0$ <br>
&emsp;&emsp; $H_1:$  at least one $\beta_i \ne 0$

**Test Statistic**

&emsp;&emsp; $F_0 = `r round(one_summary[[10]][1], digits=2)`$.

***p*-value**

&emsp;&emsp; $`r p.value.string(pf(one_summary[[10]][1], one_summary[[10]][2], one_summary[[10]][3], lower.tail = FALSE))`$.

**Rejection Region**

&emsp;&emsp; Reject if $p < \alpha$, where $\alpha=0.05$.

**Conclusion and Interpretation**

&emsp;&emsp; Reject $H_0$. There is sufficient evidence to suggest that the regression line is significant.


#### Variable added last $F$ tests

```{r}
one_typeIII_m2 <- drop1(one_m2, .~., test="F")
```

The corresponding ANOVA table is as follows

`r pander(one_typeIII_m2, style='rmarkdown')`

#### $t$ tests 

`r pander(one_summary[[4]], style='rmarkdown')`

#### 95% confidence interval for $\beta_i$
```{r}
one_ci <- as_tibble(confint(one_m2, level=0.95))
```

The confidence interval for the slope of height is (`r round(one_ci$"2.5 %"[2], digits = 2)`, `r round(one_ci$"97.5 %"[2], digits = 2)`).

The confidence interval for the slope of age is (`r round(one_ci$"2.5 %"[3], digits = 2)`, `r round(one_ci$"97.5 %"[3], digits = 2)`).

#### 95% confidence interval for $\mu_{Y|\mbox{hgt=55,age=9}}$

```{r}

# want CI for mu when hgt=55 and age=9, but this doesn't exist in dataset
hgt <- 55
age <- 9
age2 <- NA
wgt <- NA

new <- tibble(hgt, age, age2, wgt)

# combine old and new data
one_cb <- rbind(one, new)

# find predictions and CI
one_cb$Prediction <- predict(one_m2, newdata = one_cb)

one_cb$LCL <- predict(one_m2, newdata = one_cb, 
                        interval = "confidence", 
                        level = 0.95)[, 2]
one_cb$UCL <- predict(one_m2, newdata = one_cb, 
                        interval = "confidence", 
                        level = 0.95)[, 3]

# filter down to just hgt=55 and age=9
one_ci_age9 <- filter(one_cb, age==9)
one_ci_age9 <- filter(one_ci_age9, hgt==55)

```
The confidence interval for $\mu_{Y|\mbox{hgt=55,age=9}}$ is (`r round(one_ci_age9$LCL[1], digits = 2)`, `r round(one_ci_age9$UCL[1], digits = 2)`).


#### 95% prediction interval for $Y_{X_0}$ when height=55 and age=9

```{r}

# want CI for mu when hgt=55 and age=9, but this doesn't exist in dataset
hgt <- 55
age <- 9
age2 <- NA
wgt <- NA

new <- tibble(hgt, age, age2, wgt)

# combine old and new data
one_pb <- rbind(one, new)

# find predictions and CI
one_pb$Prediction <- predict(one_m2, newdata = one_pb)

one_pb$LCL <- predict(one_m2, newdata = one_pb, 
                        interval = "prediction", 
                        level = 0.95)[, 2]
one_pb$UCL <- predict(one_m2, newdata = one_pb, 
                        interval = "prediction", 
                        level = 0.95)[, 3]

# filter down to just hgt=55 and age=9
one_pi_age9 <- filter(one_pb, age==9)
one_pi_age9 <- filter(one_pi_age9, hgt==55)

```

The prediction interval for $Y_{\mbox{hgt=55,age=9}}$ is (`r round(one_pi_age9$LCL[1], digits = 2)`, `r round(one_pi_age9$UCL[1], digits = 2)`).




